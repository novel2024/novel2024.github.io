<html><head><style>a {text-decoration: none;} .content {margin-top: 50px;} .nav {position: absolute; top: 0; width: 100%; text-align: center;}</style></head><body><div class='content'><p>Beginning in 1952, with Alan Turing‚Äôs publication of a paper entitled ‚ÄúThe Chemical Basis of Morphogenesis,‚Äù scientists recognized that a simple set of mathematical formulas could dictate the variety of ways that patterns and colorings form in animals. This model is known as a reaction-diffusion model and works in a simple way: Imagine that you have multiple chemicals, which diffuse over a surface at different rates and can interact. Whereas in most cases diffusion simply creates a uniformity of a given chemical‚Äîthink how cream poured into coffee will eventually spread and dissolve and create a lighter brown liquid‚Äîwhen multiple chemicals diffuse and interact it can give rise to nonuniformity. Although this is somewhat counterintuitive, it not only occurs but also can be generated using only a simple set of equations‚Äîthus explaining the exquisite variety of patterns seen in the animal world.</p><p>Mathematical biologists have been exploring the properties of reaction-diffusion equations ever since Turing‚Äôs paper. They‚Äôve found that varying the parameters can generate the animal patterns we see. Some mathematicians have examined the ways in which the size and shape of the surface can dictate the patterns we see; as the size parameter is modified, we can easily go from such patterns as giraffe-like to those seen on Holstein cows.</p><p>This elegant model can even yield simple predictions. For example, whereas a spotted animal can have a striped tail (and very often does) according to the model, a striped animal will never have a spotted tail. And this is exactly what we see! These equations can generate the endless variation seen in nature but also show the limitations inherent in biology. The just-so of Kipling may be safely exchanged for the elegance and generality of reaction-diffusion equations.</p><p>THE UNIVERSAL ALGORITHM FOR HUMAN DECISION MAKING</p><p>STANISLAS DEHAENE</p><p>Neuroscientist, Coll√®ge de France; author, Reading in the Brain: The New Science of How We Read</p><p>The ultimate goal of science, as the French physicist Jean Baptiste Perrin once stated, should be ‚Äúto substitute visible complexity for an invisible simplicity.‚Äù Can human psychology achieve this ambitious goal: the discovery of elegant rules behind the apparent variability of human thought? Many scientists still consider psychology a ‚Äúsoft‚Äù science, whose methods and object of study are too fuzzy, too complex, and too suffused with layers of cultural complexity to ever yield elegant mathematical generalizations. Yet cognitive scientists know that this prejudice is wrong. Human behavior obeys rigorous laws of the utmost mathematical beauty and even necessity. I will nominate just one of them: the mathematical law by which we make our decisions.</p><p>All of our mental decisions appear to be captured by a simple rule that weaves together some of the most elegant mathematics of the past centuries: Brownian motion, Bayes‚Äô Law, and the Turing machine. Let‚Äôs start with the simplest of all decisions: How do we decide that 4 is smaller than 5? Psychological investigation reveals many surprises behind this simple feat. First, our performance is slow: The decision takes us nearly half a second, from the moment the digit 4 appears on a screen to the point when we respond by clicking a button. Second, our response time is highly variable from trial to trial, anywhere from 300 milliseconds to 800 milliseconds, even though we are responding to the very same digital symbol, ‚Äú4.‚Äù Third, we make errors‚Äîit sounds ridiculous, but even when comparing 4 with 5 we sometimes make the wrong decision. Fourth, our performance varies with the meaning of the objects: We are much faster and make fewer errors when the numbers are far from each other (such as 1 and 5) than when they are close (such as 4 and 5).</p><p>All of the above facts, and many more, can be explained by a single law: Our brain makes decisions by accumulating the available statistical evidence and committing to a decision whenever the total exceeds a threshold.</p><p>Let me unpack this statement. The problem the brain faces when making a decision is one of sifting the signal from the noise. The input to any of our decisions is always noisy: Photons hit our retina at random times, neurons transmit the information with partial reliability, and spontaneous neural discharges (spikes) are emitted throughout the brain, adding noise to any decision. Even when the input is a digit, neuronal recordings show that the corresponding quantity is coding by a noisy population of neurons that fires at semi-random times, with some neurons signaling ‚ÄúI think it‚Äôs 4,‚Äù others ‚Äúit‚Äôs close to 5‚Äù or ‚Äúit‚Äôs close to 3,‚Äù and so on. Because the brain‚Äôs decision system sees only unlabeled spikes, not full-fledged symbols, separating the wheat from the chaff is a genuine problem for it.</p></div><div class='nav'><a href="This-Explains-Everything_part_184.html">‚¨ÖÔ∏è</a> | <a href="index.html">üìÑ</a> | <a href="This-Explains-Everything_part_186.html">‚û°Ô∏è</a></div></body></html>