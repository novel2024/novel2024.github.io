<html><head><style>a {text-decoration: none;} .content {margin-top: 50px;} .nav {position: absolute; top: 0; width: 100%; text-align: center;}</style></head><body><div class='content'><p>In 1980, David Collingridge, an obscure academic at the University of Aston in the UK, published an important book called The Social Control of Technology, which set the tone of many subsequent debates about technology assessment. In it, he articulated what has become known as the Collingridge dilemma‚Äîthe idea that there is always a tradeoff between knowing the impact of a given technology and the ease of influencing its social, political, and innovation trajectories.</p><p>Collingridge‚Äôs basic insight was that we can successfully regulate a given technology when it‚Äôs still young and unpopular and thus probably still hiding its unanticipated and undesirable consequences‚Äîor we can wait and see what those consequences are, but then risk losing control over its regulation. Or as Collingridge himself so eloquently put it: ‚ÄúWhen change is easy, the need for it cannot be foreseen; when the need for change is apparent, change has become expensive, difficult, and time-consuming.‚Äù The Collingridge dilemma is one of the most elegant ways to explain many of the complex ethical and technological quandaries‚Äîthink drones or automated facial recognition‚Äîthat plague our globalized world.</p><p>TRUSTING TRUST</p><p>ERNST P√ñPPEL</p><p>Psychologist; neuroscientist; CEO, Human Science Center, Munich University; author, Mindworks: Time and Conscious Experience</p><p>After many years</p><p>A little gift to Edge</p><p>From the first culture.</p><p>Using the haiku</p><p>Five/seven/five syllables</p></div><div class='nav'><a href="This-Explains-Everything_part_131.html">‚¨ÖÔ∏è</a> | <a href="index.html">üìÑ</a> | <a href="This-Explains-Everything_part_133.html">‚û°Ô∏è</a></div></body></html>