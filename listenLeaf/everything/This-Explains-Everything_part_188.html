<html><head><style>a {text-decoration: none;} .content {margin-top: 50px;} .nav {position: absolute; top: 0; width: 100%; text-align: center;}</style></head><body><div class='content'><p>Chance as an Unseen Force</p><p>Eighty-three years later, Carl Jung published a similar idea in his well-known essay ‚ÄúSynchronicity, An Acausal Connecting Principle.‚Äù He postulated the existence of a hidden force responsible for the occurrence of seemingly related events that otherwise appear to have no causal connection. The initial story of the six fish encounters is Jung‚Äôs, taken from his book. He finds this string of events unusual‚Äîtoo unusual to be ascribable to chance. He thinks something else must be going on and labels it the acausal connecting principle.</p><p>Persi Diaconis, Mary V. Sunseri Professor of Statistics and Mathematics at Stanford and a former professor of mine, thinks critically about Jung‚Äôs example: Suppose we encounter the concept of fish once a day on average, according to what statisticians call a Poisson process (another fish reference!). The Poisson process is a standard mathematical model for counts‚Äîfor example, radioactive decay seems to follow a Poisson process. The model presumes a certain fixed rate at which observations appear on average, and otherwise they are random. So we can consider a Poisson process for Jung‚Äôs example with a long-run average rate of one observation per twenty-four hours and calculate the probability of seeing six or more observations of fish in a twenty-four-hour window. Diaconis finds the chance to be about 22 percent. Seen from this perspective, Jung shouldn‚Äôt have been surprised.</p><p>The Statistical Revolution: Chance in Models of Data Generation</p><p>Only about two decades after Tolstoy penned his lines about sheep, the English mathematician Karl Pearson brought about a statistical revolution in scientific thinking with a new idea of how observations arose‚Äîthe same idea used by Diaconis in his probability calculation. Pearson suggested that nature presents data from an unknown distribution but with some random scatter. His insight was that this is a different concept from measurement error, which adds additional error when the observations are actually recorded.</p><p>Before Pearson, science dealt with things that were ‚Äúreal,‚Äù such as laws describing the movement of the planets or blood flow in horses (to use examples from David Salsburg‚Äôs book, The Lady Tasting Tea). What Pearson made possible was a probabilistic conception of the world. Planets didn‚Äôt follow laws with exact precision, even after accounting for measurement error. The exact course of blood flow differed in different horses, but the horse circulatory system wasn‚Äôt purely random. In estimating distributions rather than the phenomena themselves, we are able to abstract a more accurate picture of the world.</p><p>Chance Described by Probability Distributions</p><p>That measurements themselves have a probability distribution was a marked shift from confining randomness to the errors in the measurement. Pearson‚Äôs conceptualization is useful because it permits us to estimate whether what we see is likely or not, under the assumptions of the distribution. This reasoning is now our principal tool for judging whether or not we think an explanation is likely to be true.</p><p>We can, for example, quantify the likelihood of drug effectiveness or carry out particle detection in high-energy physics. Is the distribution of the mean-response difference between drug treatment and control groups centered at zero? If that seems likely, we can be skeptical of the drug‚Äôs effectiveness. Are candidate signals so far from the distribution for known particles that they must be from a different distribution, suggesting a new particle? Detecting the Higgs boson requires such a probabilistic understanding of the data, to differentiate Higgs signals from other events. In all these cases, the key is that we want to know the characteristics of the underlying distribution that generated the phenomenon of interest.</p><p>Pearson‚Äôs incorporation of randomness directly into the probability distribution enables us to think critically about likelihoods and quantify our confidence in particular explanations. We can better evaluate when what we see has special meaning and when it does not, permitting us to better reach our ‚Äúhuman aims.‚Äù</p></div><div class='nav'><a href="This-Explains-Everything_part_187.html">‚¨ÖÔ∏è</a> | <a href="index.html">üìÑ</a> | <a href="This-Explains-Everything_part_189.html">‚û°Ô∏è</a></div></body></html>