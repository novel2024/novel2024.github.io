<html><head><style>a {text-decoration: none;} .content {margin-top: 50px;} .nav {position: absolute; top: 0; width: 100%; text-align: center;}</style></head><body><div class='content'><p>In the presence of noise, how should one make a reliable decision? The mathematical solution to that problem was first addressed by Alan Turing, when he was cracking the Enigma code at Bletchley Park. Turing found a small glitch in the Enigma machine, which meant that some of the German messages contained small amounts of information, but unfortunately too little for him to be certain of the underlying code. He realized that Bayes‚Äô Law could be exploited to combine all the independent pieces of evidence. Skipping the math, Bayes‚Äô Law provides a simple way to sum all of the successive hints, plus whatever prior knowledge we have, in order to obtain a combined statistic that tells us what the total evidence is.</p><p>With noisy inputs, this sum fluctuates up and down, as some incoming messages support the conclusion while others merely add noise. The outcome is what mathematicians call a random walk‚Äîa fluctuating march of numbers as a function of time. In our case, however, the numbers have a currency: They represent the likelihood that one hypothesis is true (e.g., the probability that the input digit is smaller than 5). Thus, the rational thing to do is to act as a statistician and wait until the accumulated statistic exceeds a threshold probability value. Setting it to p = 0.999 would mean that we have 1 chance in 1,000 to be wrong.</p><p>Note that we can set this threshold to any arbitrary value. However, the higher we put it, the longer we have to wait for a decision. There is a speed/accuracy tradeoff: We can wait a long time and make a highly accurate but conservative decision, or we can hazard a response earlier but at the cost of making more errors. Whatever our choice, we will always make a few errors.</p><p>Suffice it to say that the decision algorithm I sketched‚Äîwhich simply describes what any rational creature should do in the face of noise‚Äîis now considered a fully general mechanism for human decision making. It explains our response times, their variability, and the entire shape of their distribution. It describes why we make errors, how errors relate to response time, and how we set the speed/accuracy tradeoff. It applies to all sorts of decisions, from sensory choices (Did I see movement or not?) to linguistics (Did I hear ‚Äúdog‚Äù or ‚Äúbog‚Äù?) to higher-level conundrums (Should I do this task first or second?). And in more complex cases, such as performing a multidigit calculation or a series of tasks, the model characterizes our behavior as a sequence of accumulate-and-threshold steps, which turns out to be an excellent description of our serial, effortful Turing-like computations.</p><p>Furthermore, this behavioral description of decision making is now leading to major progress in neuroscience. In the monkey brain, neurons can be recorded whose firing rates index an accumulation of relevant sensory signals. The theoretical distinction between evidence accumulation and threshold helps parse out the brain into specialized subsystems that make sense from a decision-theoretic viewpoint.</p><p>As with any elegant scientific law, many complexities are waiting to be discovered. There is probably not just one accumulator but many, as the brain accumulates evidence at each of several successive levels of processing. Indeed, the human brain increasingly fits the bill for a superb Bayesian machine that makes massively parallel inferences and microdecisions at every stage. Many of us think our sense of confidence, stability, and even conscious awareness may result from such higher-order cerebral ‚Äúdecisions‚Äù and will ultimately fall prey to the same mathematical model. Valuation is also a key ingredient, one that I skipped, although it demonstrably plays a crucial role in weighing our decisions. Finally, the system is ripe with a-prioris, biases, time pressures, and other top evaluations that draw it away from strict mathematical optimality.</p><p>Nevertheless, as a first approximation, this law stands as one of the most elegant and productive discoveries of 20th-century psychology: Humans act as near-optimal statisticians, and our decisions correspond to an accumulation of the available evidence up to some threshold.</p><p>LORD ACTON‚ÄôS DICTUM</p><p>MIHALY CSIKSZENTMIHALYI</p><p>Distinguished Professor of Psychology and Management, Claremont Graduate University; founding codirector of CGU‚Äôs Quality of Life Research Center; author, Flow: The Psychology of Optimal Experience</p></div><div class='nav'><a href="This-Explains-Everything_part_185.html">‚¨ÖÔ∏è</a> | <a href="index.html">üìÑ</a> | <a href="This-Explains-Everything_part_187.html">‚û°Ô∏è</a></div></body></html>