<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Document</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/5.1.0/css/bootstrap.min.css">
</head>
<body>
<div class="container mt-5">
    
    <p> It has arrived just in time. Recasting our model ofhow the mind functions has lately become an urgent necessity, as we findourselves increasingly squeezed by two opposing forces: we need ever more tothink outside the brain, even as we have become ever more stubbornlycommitted to the brainbound approach.First, as to that growing need to think outside the brain: as many of us canreadily recognize—in the accelerated pace of our days and the escalatingcomplexity of our duties at school and work—the demands on our thinking areratcheting up. There’s more information we must deal with.</p>
    
    <p> The information wehave to process is coming at us faster. And the kind of information we must dealwith is increasingly specialized and abstract. This difference in kind is especiallysignificant. The knowledge and skills that we are biologically prepared to learnhave been outstripped by the need to acquire a set of competencies that come farless naturally and are acquired with far more difficulty.</p>
    
    <p> David Geary, a professorof psychology at the University of Missouri, makes a useful distinction between“biologically primary” and “biologically secondary” abilities. Human beings, hepoints out, are born ready to learn certain things: how to speak the language ofthe local community, how to find their way around a familiar landscape, how tonegotiate the challenges of small-group living. We are not born to learn theintricacies of calculus or the counterintuitive rules of physics; we did not evolveto understand the workings of the financial markets or the complexities of globalclimate change. And yet we dwell in a world where such biologically secondarycapacities hold the key to advancement, even survival.</p>
    
    <p> The demands of themodern environment have now met, and exceeded, the limits of the biologicalbrain.For a time, it’s true, humanity was able to keep up with its own ever-advancing culture, resourcefully finding ways to use the biological brain better.As their everyday environments grew more intellectually demanding, peopleresponded by upping their cognitive game. Continual engagement with themental rigors of modern life—along with improving nutrition, rising livingconditions, and reduced exposure to infectious disease and other pathogens—produced a century-long climb in average IQ score, as measured by intelligencetests taken by people all over the globe.</p>
    
    <p> But this upward trajectory is nowleveling off. In recent years, IQ scores have stopped rising, or have even begunto drop, in countries like Finland, Norway, Denmark, Germany, France, andBritain. Some researchers suggest that we have now pushed our mentalequipment as far as it can go. It may be that “our brains are already working atnear-optimal capacity,” note Nicholas Fitz and Peter Reiner, writing in thejournal Nature.</p>
    
    <p> Efforts to wrest more intelligence from this organ, they add,“bump up against the hard limits of neurobiology.”As if to protest this unwelcome truth, attempts to subvert such limits havereceived growing attention in recent years. Commercial brain-training regimenslike Cogmed, Lumosity, and BrainHQ have attracted many who desire toimprove their memory and increase their focus; Lumosity alone claims 100million registered users in 195 countries. At the same time, so-calledneuroenhancement—innovations like “smart pills” and electrical brainstimulation that claim to make their users more intelligent—have drawnbreathless media coverage, as well as extensive investment from pharmaceuticaland biotechnology companies.</p>
    
    <p>So far, however, these approaches have yielded little more thandisappointment and dashed hopes. A team of scientists who set out to evaluateall the peer-reviewed intervention studies cited on the websites of leading brain-training companies could find “little evidence” within those studies “that trainingimproves everyday cognitive performance.” Engaging in brain training doesimprove users’ performance—but only on exercises highly similar to the onesthey’ve been practicing. The effect does not seem to transfer to real-life activitiesinvolving attention and memory.</p>
    
    <p> A 2019 study of Cogmed concluded that suchtransfer “is rare, or possibly inexistent.” A 2017 study of Lumosity determinedthat “training appears to have no benefits in healthy young adults”; similarlydismal results have been reported for older individuals. In 2016, Lumosity wasforced to pay a $2 million fine for deceptive advertising to the US Federal TradeCommission. Smart pills haven’t fared much better; a clinical trial of one“nootropic” drug popular among Silicon Valley tech workers found that a cup ofcoffee was more effective at boosting memory and attention.</p>
    
    <p>Medications and technologies that might, someday, actually enhanceintelligence remain in the early stages of laboratory testing. The best way—and,at least for now, the only way—for us to get smarter is to get better at thinkingoutside the brain. Yet we dismiss or disparage this kind of cognition, to theextent that we consider it at all. Our pronounced bias in favor of brainboundthinking is long-standing and well entrenched—but a bias is all it is, and one thatcan no longer be supported or sustained.</p>
    
    <p> The future lies in thinking outside thebrain.WE CAN BETTER grasp the future of thinking outside the brain by taking a lookback at the time when the idea first emerged. In 1997, Andy Clark—then aprofessor of philosophy at Washington University in St. Louis, Missouri—lefthis laptop behind on a train.</p>
    
</div>
</body>
</html>