<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Document</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/5.1.0/css/bootstrap.min.css">
</head>
<body>
<div class="container mt-5">
    
    <p>are precise and specific when describing what we feel. Accurately distinguishing among interoceptive sensations is associated with making sounder decisions,
acting less impulsively, and planning ahead more successfully—perhaps because it gives us a clearer sense of what we need and what we want.
Sensing and labeling our internal sensations allows them to function more efficiently as our somatic rudder, steering a nimble course through the many decisions of our days. But does the body really have anything to contribute to our thinking—to processes we usually regard as taking place solely in our heads? It does.</p>
    
    <p> In fact, recent research suggests a rather astonishing possibility:
the body can be more rational than the brain. Recall that, in the study conducted by John Coates, traders with keener interoceptive awareness earned more money: that is, they made more rational choices about buying and selling, as judged by the market, than investors who were less attuned to their bodies.
Outcomes like these may result from the fact that the body is not subject to the cognitive biases that so often distort our conscious thought—the glitches that appear to be hardwired into the human brain.
Take, for example, our stubborn tendency to insist on notions of fairness, even at the cost of spiting ourselves.</p>
    
    <p> In the “ultimatum game,” an experimental paradigm often employed by behavioral economists, participants are paired up with a partner; one of the partners is given a pot of money to divide as she wishes. The other partner may then choose to accept or reject the proposed division. Accepting even a very low offer is more rational than rejecting the offer outright, which leaves the receiving partner with nothing. Yet studies consistently find that many players decline low offers out of a sense of being unjustly wronged—a sense that they should have gotten more.</p>
    
    <p>
In a study published in 2011, researchers from Virginia Tech scanned the brains of two groups of people as they played the ultimatum game: a group who regularly practiced meditation, and a group of control subjects who did not meditate. The scans revealed that in the meditators, the insula—the brain’s interoceptive center—was active during game play, indicating that they were relying on their bodies’ signals to make their decisions. The controls exhibited a different pattern: their scans showed activity in the prefrontal cortex, the part of the brain that makes conscious judgments about what’s fair and unfair. The two groups also diverged in their behavior, researchers reported.</p>
    
    <p> The interoceptively aware meditators were more likely to elect the rational option of accepting a low offer over no money at all, while the cogitating controls were more apt to snub a proposed division that was tilted in their partners’ favor.
Among social scientists, a character named Homo economicus is often invoked; the term describes an idealized agent who always makes the perfectly logical and rational choice. This figure has proved hard to find in the real world —and yet, the Virginia Tech researchers write, “in this study, we identified a population of human beings who play the ultimatum game more like Homo economicus.” In a tone of some surprise, they continue, “Experienced meditators were willing to accept even the most asymmetrical offers on more than half of the trials, whereas control members of Homo sapiens did so in just over one- quarter of the trials.</p>
    
    <p>” The bias shown by the non-meditators in the Virginia Tech study is one of many catalogued by behavioral economists. Others include the anchoring effect,
in which we rely too heavily as a point of reference on the first piece of information we encounter; the availability heuristic, in which we overestimate the likelihood of events that come more readily to mind; and the self-serving bias, in which our personal preferences incline our beliefs in an overly optimistic direction. What to do about such biases? The strategy of many economists and psychologists has been to inform people of their existence, then recommend that people monitor their mental activity for signs that their thinking is being swayed.
In the terminology popularized by psychologist Daniel Kahneman, we’re supposed to use rational, reflective “System 2” thinking to override the bias- riddled responses of the faster “System 1.</p>
    
    <p>” Mark Fenton-O’Creevy, a professor of organizational behavior at The Open University in the UK, was once a believer in this highly brainbound approach.
Then he conducted a series of interviews with expert traders at six investment banks and found that they almost never proceeded in this fashion. Instead, the traders told him, they relied heavily on the sensations they felt stirring within their own bodies. One investor described the process to Fenton-O’Creevy in particularly visceral terms.</p>
    
    <p> “You have to trust your instincts, and a lot of the decisions are split second, so you need to know where the edge is and what you are going to do about it,” he related. “Having a feeling is like having whiskers,
like being a deer; just hearing something that the human ear can’t hear and all of a sudden you’re on edge. Something somewhere just gave you a slight shiver,
but you’re not quite sure what, but it’s something to be careful about,
something’s around.” Successful financiers are exquisitely sensitive to these subtle physiological cues, Fenton-O’Creevy discovered.</p>
    
    <p> What’s more, they seem to pick up on such signals early on, just as the feelings start to emerge—and act on them in that moment, rather than dismissing them, suppressing them, or holding them off for later inspection. Because this approach proceeds rapidly and with little mental effort, it’s much better suited to addressing the complex, fast-paced decisions that many of us are called upon to make, says Fenton-O’Creevy. And going around our cognitive biases in this way is more effective than laboriously trying to correct them. “De-biasing approaches which rely primarily on shifting cognition from System 1 to System 2 are unlikely to succeed,” he maintains.</p>
    
    <p>
“The human capacity for self-monitoring and effortful System 2 cognition is limited and is rapidly depleted. Attempts to reduce biases by learning about biases and engaging in self-monitoring rapidly come up against human cognitive limits.” Fenton-O’Creevy has experimented with techniques intended to increase investors’ interoceptive awareness—through the practice of mindfulness, and through the provision of frequent physiological feedback. In his lab, he had participants play a specially designed video game called Space Investor; as part of the game, they periodically estimated how fast their hearts were beating.</p>
    
</div>
</body>
</html>