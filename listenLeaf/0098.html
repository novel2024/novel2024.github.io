<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Document</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/5.1.0/css/bootstrap.min.css">
</head>
<body>
<div class="container mt-5">
    
    <p> Family Playlists provides support by sending the “family partners” a link via a text message; the link takes them to a Web page describing the “collaborative learning activity” in which they are to participate. Family members use this same platform to provide feedback to their child’s teacher about how well the child understood and explained the lesson.
PowerMyLearning has now implemented Family Playlists in more than one hundred schools nationwide; the organization’s CEO, Elisabeth Stock, notes that an internal research study found that students using the tool made gains in math equivalent to four months of additional learning. Even more important, she adds,
teachers report that their relationships with students’ families have improved,
and students themselves are more engaged and enthusiastic about learning.</p>
    
    <p>
Teaching is a mode of social interaction we can deliberately deploy in order to think more intelligently. There’s another form of social exchange that we can use to our advantage, one that comes just as naturally to the human animal:
arguing.
 THE STUDY was positively devilish in its design.
Participants were asked, first, to solve a series of logic puzzles: “A produce shop sells a variety of fruits and vegetables, some of which are organic and some of which are not.</p>
    
    <p> The apples sold by this shop are not organic. Which of the following statements about the shop’s wares are true? Provide a reason for each answer. 1) All the fruits are organic; 2) None of the fruits are organic; 3) Some of the fruits are organic; 4) Some of the fruits are not organic; 5) We cannot tell anything for sure about whether the fruits in this shop are organic.” After solving the puzzles, study participants were then asked to evaluate the responses provided by other participants—that is, to judge whether the reasons given by others seemed valid or not.</p>
    
    <p>
The trick: one of the answers presented in this second round did not issue from someone else but rather was an answer the participant herself had supplied in the first round. Some participants recognized their own response, but many others did not. What happened next was fascinating. More than half of those who believed they were evaluating someone else’s response rejected as invalid the answer they themselves had put forth! They were especially likely to reject their own response when they had, in fact, offered a logically invalid answer originally.</p>
    
    <p> In other words, they applied more critical analysis to (what they thought were) other people’s arguments than to their own—and this scrutiny made them more accurate.
There was a purpose behind the deviousness of the researchers who designed this study. Hugo Mercier, a cognitive scientist at the National Center for Scientific Research (CNRS) in Paris, and his coauthors were out to expose the peculiar nature of human reason. As we’ve seen, people often perform poorly when asked to think in a logical fashion.</p>
    
    <p> Recall that fewer than 10 percent of people who take the standard (non-social) form of the Wason Selection Task complete it correctly; performance on other standardized measures of reasoning,
like the Thinking Skills Assessment and the Cognitive Reflection Test, is similarly mediocre, even among people who are generally well educated and even among people who have been expressly trained in argumentation and rhetoric.
An entire academic field is devoted to cataloguing the cognitive biases and other mental distortions that interfere with rational thinking. There is our well- documented confirmation bias, for example—the tendency to selectively seek out and believe evidence that supports our prior beliefs. Originally named by none other than Peter Wason, confirmation bias has been further elaborated by the psychologist Daniel Kahneman.</p>
    
    <p> In his 2011 book Thinking, Fast and Slow,
Kahneman observed, “Contrary to the rules of philosophers of science, who advise testing hypotheses by trying to refute them, people (and scientists, quite often) seek data that are likely to be compatible with the beliefs they currently hold.” The human mind, he lamented, is “a machine for jumping to conclusions.” But why should this be so? Why would the most intelligent creatures on the planet be hobbled by these built-in mental defects? Kahneman and others who study cognitive biases have no convincing answer to this question, according to Hugo Mercier; they treat human reason as if it were a “flawed superpower,” at once impressively capable and strangely prone to breaking down. In the view of these psychologists, such glitches in the mind’s ability to reason are inherent and unavoidable; the most we can do, they say, is to remain alert for the emergence of bias, and then endeavor to correct it.</p>
    
    <p>
Mercier begs to differ. With his collaborator Dan Sperber, also a cognitive scientist at CNRS, he has proposed a provocative alternative—different in its explanation for reason’s afflictions, and different in its recommended remedy.
We did not evolve to solve tricky logic puzzles on our own, they point out, and so we shouldn’t be surprised by the fact that we’re no good at it, any more than by the fact that we’re no good at breathing underwater. What we did evolve to do is persuade other people of our views, and to guard against being misled by others.</p>
    
</div>
</body>
</html>